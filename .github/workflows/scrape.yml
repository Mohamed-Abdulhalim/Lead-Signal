name: scrape

on:
  schedule:
    - cron: "0 11,23 * * *"
  workflow_dispatch:

env:
  PYTHONDONTWRITEBYTECODE: "1"
  PIP_NO_CACHE_DIR: "off"
  TZ: "Africa/Cairo"
  SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
  SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg unzip
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Scrape (headless)
        run: |
          python maps.py \
            --categories-file categories.txt \
            --location "Cairo, Egypt" \
            --max-places 20 \
            --output TheResultss.csv \
            --headless \
            --log INFO

      - name: Clean CSV
        run: |
          python csv_cleaner.py --in TheResultss.csv --out TheResultss_clean.csv

      - name: Push to Supabase
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}
        run: |
          python supabase_push.py --csv TheResultss_clean.csv
